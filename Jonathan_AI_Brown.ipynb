{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import docx\n",
    "import openai\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "class BrownEmulator:\n",
    "    def __init__(self, api_key: str, folder_path: str):\n",
    "        \"\"\"Initialize the Brown emulator with API key and folder path.\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.folder_path = folder_path\n",
    "        openai.api_key = api_key\n",
    "        self.vectorstore = None\n",
    "        \n",
    "    def extract_from_pdf(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from PDF files.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                return ' '.join([page.extract_text() for page in reader.pages])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {file_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def extract_from_docx(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from DOCX files.\"\"\"\n",
    "        try:\n",
    "            doc = docx.Document(file_path)\n",
    "            return ' '.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOCX {file_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def extract_from_txt(self, file_path: str) -> str:\n",
    "        \"\"\"Extract text from TXT files.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing TXT {file_path}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def extract_all_texts(self) -> str:\n",
    "        \"\"\"Extract text from all supported files in the folder.\"\"\"\n",
    "        all_text = \"\"\n",
    "        file_handlers = {\n",
    "            '.pdf': self.extract_from_pdf,\n",
    "            '.docx': self.extract_from_docx,\n",
    "            '.txt': self.extract_from_txt\n",
    "        }\n",
    "        \n",
    "        for filename in os.listdir(self.folder_path):\n",
    "            file_path = os.path.join(self.folder_path, filename)\n",
    "            ext = os.path.splitext(filename)[1].lower()\n",
    "            \n",
    "            if ext in file_handlers:\n",
    "                print(f\"Processing {filename}...\")\n",
    "                text = file_handlers[ext](file_path)\n",
    "                all_text += f\"\\n{text}\"\n",
    "                \n",
    "        return all_text\n",
    "\n",
    "    def create_index(self, chunk_size: int = 1000, chunk_overlap: int = 100) -> None:\n",
    "        \"\"\"Create a searchable index from the extracted text.\"\"\"\n",
    "        try:\n",
    "            text = self.extract_all_texts()\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap=chunk_overlap\n",
    "            )\n",
    "            docs = text_splitter.create_documents([text])\n",
    "            \n",
    "            embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "            self.vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "            print(\"Index created successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating index: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_context(self, query: str, top_k: int = 3) -> str:\n",
    "        \"\"\"Retrieve relevant context for a query.\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"Please create an index first using create_index()\")\n",
    "            \n",
    "        docs = self.vectorstore.similarity_search(query, k=top_k)\n",
    "        return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    def query(self, user_query: str, max_retries: int = 3) -> str:\n",
    "        \"\"\"Query the system with error handling and retries.\"\"\"\n",
    "        try:\n",
    "            context = self.get_context(user_query)\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            You are emulating Jonathan A. C. Brown, a scholar of Islamic thought and Hadith studies. \n",
    "            Use the following context from Brown's writings to inform your response.\n",
    "            \n",
    "            Context:\n",
    "            {context}\n",
    "            \n",
    "            Question:\n",
    "            {user_query}\n",
    "            \n",
    "            Respond in Brown's academic style, drawing from the provided context and your understanding \n",
    "            of Islamic scholarship. Include relevant technical terms and conceptual frameworks when appropriate.\n",
    "            \"\"\"\n",
    "            \n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-4\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"system\", \"content\": prompt}\n",
    "                        ],\n",
    "                        temperature=0.7\n",
    "                    )\n",
    "                    return response.choices[0].message.content\n",
    "                    \n",
    "                except openai.error.RateLimitError:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        time.sleep(20 * (attempt + 1))  # Exponential backoff\n",
    "                    else:\n",
    "                        raise\n",
    "                        \n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {e}\"\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the emulator\n",
    "    emulator = BrownEmulator(\n",
    "        api_key=\"your-api-key-here\",\n",
    "        folder_path=\"path/to/your/documents\"\n",
    "    )\n",
    "    \n",
    "    # Create the index\n",
    "    emulator.create_index()\n",
    "    \n",
    "    # Example query\n",
    "    response = emulator.query(\"What is Brown's perspective on the prevalence of matn criticism in the Sunni tradition prior to the canonization of Bukhari and Muslim's Sahihayn?\")\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
